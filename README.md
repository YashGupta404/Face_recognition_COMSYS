# ğŸ¤– Face Recognition & Gender Classification (FACECOM)

A complete deep learning pipeline built for the **FACECOM 2025 Challenge**, supporting:

- ğŸ‘©â€ğŸ¦° **Task A:** Gender Classification  
- ğŸ§‘â€ğŸ’» **Task B:** Face Recognition under Distorted Conditions

> âœ… All models are hosted on Hugging Face Hub â€“ no manual downloads required.  
> Just place your test folder, run the script, and get evaluation metrics instantly!

---

## ğŸ“ Project Structure

```
Face_recognition_COMSYS/
â”œâ”€â”€ train_a/                         # Task A - Gender Classification
â”‚   â”œâ”€â”€ test.py                      # Evaluation script
â”‚   â”œâ”€â”€ Task_A.ipynb                 # Training notebook
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ train_b/                         # Task B - Face Recognition
â”‚   â”œâ”€â”€ predict_test.py              # Evaluation script
â”‚   â”œâ”€â”€ Task_B.ipynb                 # Training notebook
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ report.pdf                       # Technical Report
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â””â”€â”€ .gitattributes
```

---

## ğŸ§‘â€ğŸ¦° TASK A â€“ Gender Classification

### ğŸ“ Model Architecture

- âœ… **Transfer Learning:** VGG16 / ResNet50 backbone
- âœ… **Binary Classification:** Male vs Female
- âœ… **Input Shape:** 150x150 RGB
- âœ… **Optimizer:** Adam
- âœ… **Callbacks:** EarlyStopping, ReduceLROnPlateau
- âœ… **Data Augmentation:** Rotation, Flip, Brightness, Zoom

### ğŸ“‚ Expected Test Folder Structure

```
test/
â”œâ”€â”€ male/
â”‚   â”œâ”€â”€ image1.jpg
â”‚   â””â”€â”€ ...
â””â”€â”€ female/
    â”œâ”€â”€ image2.jpg
    â””â”€â”€ ...
```

### ğŸ”§ How to Run

```bash
cd train_a
pip install -r requirements.txt
# â¬‡ï¸ Make sure to update the TEST_DIR variable inside test.py with your test folder path
python test.py
```

âœ… This Will:

- ğŸ” Automatically download model & preprocessor from Hugging Face  
- ğŸ“Š Output metrics (Accuracy, Precision, Recall, F1 Score)  
- ğŸ’¾ Save metrics to `test_metrics.json`  

---

## ğŸ§  TASK B â€“ Face Recognition under Distorted Conditions

### ğŸ“ Model Architecture

- âœ… **Backbones:** EfficientNetB3, ResNet50, MobileNetV2
- âœ… **Loss:** ArcFace (metric learning for angular separation)
- âœ… **Optimizer:** Sharpness-Aware Minimization (SAM) + Cosine LR
- âœ… **Input Shape:** 96x96 RGB
- âœ… **Ensemble Voting** via embedding distances (k-NN)

### ğŸ“‚ Expected Test Folder Structure

```
test/
â”œâ”€â”€ 001_frontal/
â”‚   â”œâ”€â”€ 001_frontal.jpg
â”‚   â””â”€â”€ distortion/
â”‚       â”œâ”€â”€ blur.jpg
â”‚       â””â”€â”€ lowlight.jpg
â”œâ”€â”€ 002_frontal/
â”‚   â”œâ”€â”€ 002_frontal.jpg
â”‚   â””â”€â”€ distortion/
â”‚       â”œâ”€â”€ fog.jpg
â”‚       â””â”€â”€ ...
```

### ğŸ”§ How to Run

```bash
cd train_b
pip install -r requirements.txt
# â¬‡ï¸ Make sure to update the TEST_FOLDER variable inside predict_test.py with your test folder path
python predict_test.py
```

âœ… This Will:

- ğŸ“¦ Automatically load model weights & LabelEncoder from Hugging Face  
- ğŸ“Š Evaluate Top-1 accuracy, Precision, Recall, F1  
- ğŸ’¾ Save metrics to `test_metrics.json`

---

## â˜ï¸ Model Hosting on Hugging Face

All models are publicly hosted on:

ğŸ‘‰ https://huggingface.co/YashGupta05/facecom-task-b-weights

**Hosted Files:**

- `Task_A_.keras` â€” Gender classifier
- `preprocessor_task_A.pkl` â€” Preprocessing config for Task A
- `model.keras` â€” Face recognition model
- `preprocess.pkl` â€” LabelEncoder for Task B

No manual download needed. Scripts handle loading automatically.

---

## ğŸ’¡ Highlights

- âœ… No hardcoded filenames or manual downloads  
- ğŸ“¦ Fully automatic Hugging Face model loading  
- ğŸ§  ArcFace + Transfer Learning architectures  
- âš¡ Fast, GPU-optimized execution on Colab  
- ğŸ§ª Ready for real-world distortion conditions

---

## ğŸ¤ Contributors

- **Yash Gupta** â€“ Developed Task B  
- **Riti Kant Juhi** â€“ Developed Task A  
- **Rohit Roy** â€“ Wrote Technical Report

---

## ğŸ“œ License

Licensed under the [Apache 2.0 License](https://www.apache.org/licenses/LICENSE-2.0).
